<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>handsomeli</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="读论文1DIFFUSION CONVOLUTIONAL RECURRENT NEURAL NETWORK: DATA-DRIVEN TRAFFIC FORECASTINGICLR 2018的论文，阅读体验比较好。 还是老问题： ​    给定一个交通网络（用一个图来表示，边权表示两个节点（两个路口）之间的距离），然后给你一段时间内每个路口的特征（T * N * Feature），要你输出（预测）">
<meta property="og:type" content="article">
<meta property="og:title" content="handsomeli">
<meta property="og:url" content="http://example.com/2022/03/07/%E8%AF%BB%E8%AE%BA%E6%96%871/index.html">
<meta property="og:site_name" content="handsomeli">
<meta property="og:description" content="读论文1DIFFUSION CONVOLUTIONAL RECURRENT NEURAL NETWORK: DATA-DRIVEN TRAFFIC FORECASTINGICLR 2018的论文，阅读体验比较好。 还是老问题： ​    给定一个交通网络（用一个图来表示，边权表示两个节点（两个路口）之间的距离），然后给你一段时间内每个路口的特征（T * N * Feature），要你输出（预测）">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2022/03/07/%E8%AF%BB%E8%AE%BA%E6%96%871/graphwavenet1.png">
<meta property="og:image" content="http://example.com/2022/03/07/%E8%AF%BB%E8%AE%BA%E6%96%871/graphwavenet2.png">
<meta property="og:image" content="http://example.com/2022/03/07/%E8%AF%BB%E8%AE%BA%E6%96%871/graphwavenet3.png">
<meta property="og:image" content="http://example.com/2022/03/07/%E8%AF%BB%E8%AE%BA%E6%96%871/MTGNN1.png">
<meta property="og:image" content="http://example.com/2022/03/07/%E8%AF%BB%E8%AE%BA%E6%96%871/MTGNN2.png">
<meta property="og:image" content="http://example.com/2022/03/07/%E8%AF%BB%E8%AE%BA%E6%96%871/MTGNN3.png">
<meta property="og:image" content="http://example.com/2022/03/07/%E8%AF%BB%E8%AE%BA%E6%96%871/STSGCN.png">
<meta property="og:image" content="http://example.com/2022/03/07/%E8%AF%BB%E8%AE%BA%E6%96%871/STSGCN2.png">
<meta property="article:published_time" content="2022-03-07T11:18:21.326Z">
<meta property="article:modified_time" content="2022-03-07T11:21:47.895Z">
<meta property="article:author" content="lpf">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2022/03/07/%E8%AF%BB%E8%AE%BA%E6%96%871/graphwavenet1.png">
  
    <link rel="alternate" href="/atom.xml" title="handsomeli" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">handsomeli</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-读论文1" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/03/07/%E8%AF%BB%E8%AE%BA%E6%96%871/" class="article-date">
  <time class="dt-published" datetime="2022-03-07T11:18:21.326Z" itemprop="datePublished">2022-03-07</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <hr>
<h2 id="读论文1"><a href="#读论文1" class="headerlink" title="读论文1"></a>读论文1</h2><h1 id="DIFFUSION-CONVOLUTIONAL-RECURRENT-NEURAL-NETWORK-DATA-DRIVEN-TRAFFIC-FORECASTING"><a href="#DIFFUSION-CONVOLUTIONAL-RECURRENT-NEURAL-NETWORK-DATA-DRIVEN-TRAFFIC-FORECASTING" class="headerlink" title="DIFFUSION CONVOLUTIONAL RECURRENT NEURAL NETWORK: DATA-DRIVEN TRAFFIC FORECASTING"></a>DIFFUSION CONVOLUTIONAL RECURRENT NEURAL NETWORK: DATA-DRIVEN TRAFFIC FORECASTING</h1><p>ICLR 2018的论文，阅读体验比较好。</p>
<p>还是老问题：</p>
<p>​    给定一个交通网络（用一个图来表示，边权表示两个节点（两个路口）之间的距离），然后给你一段时间内每个路口的特征（T * N * Feature），要你输出（预测）未来一段时间内这些节点的特征（T‘ * N * Feature），特征如速度，车流量等。</p>
<p>还是要分为时间和空间考虑。</p>
<p>空间：</p>
<p>空间部分参考了随机游走，设$D_o$为出度矩阵(即只有对角线元素表示点的出度，其他都为0)，P为一个n*n二维矩阵表示从i出发，最后在j结束的概率。那么$P = \sum_{k=0}^{\infty} \alpha (1-\alpha)^k (D_o^{-1}W)^k$，W矩阵是文章中提到衡量两个节点距离的高斯核。</p>
<p>设X是输入向量N*P，P是特征数，对于每一个特征p分别考虑，定义卷积核$G f_\theta$  :</p>
<p>$X_{:,p}*Gf_\theta=\sum_{k=0}^{K-1}(\theta_{k,1}(D_o^{-1}W)^k+\theta_{k,2}(D_i^{-1}W^T)^k)X_{:,p}$</p>
<p>其中我理解的是$\theta_{k,1/2}$是学习参数，共有K*2个学习参数。然后前面一半是正向随机游走，后一半是反向随机游走。</p>
<p>接下来是扩散卷积层，定义$\Theta_{p,q}$表示从p个特征映射到q个特征的K*2个学习参数，同样的，只考虑某个特征q，输出的式子是：</p>
<p>$H_{:,q}=a(\sum_{p=1}^P X_{:,p} * Gf_{\Theta_{p,q}})$，q在[1,Q]之间</p>
<p>时间：</p>
<p>时间层很大程度上参考了LSTM中的GRU，不同之处在于学习的参数矩阵W全部变成上述的卷积核了。设$X^t$表示t时刻的输入（实际上这时候的$X_t$应该是原始的数据通过了空间层之后生成的）</p>
<p>$r^t=\sigma(\Theta_r*G[X^t||H^{t-1}]+b_r)$</p>
<p>$u^t=\sigma(\Theta_u*G[X^t||H^{t-1}]+b_u)$</p>
<p>$C^t=tanh(\Theta_C*G[X^t || (r^t\bigodot H^{t-1})]+b_c)$</p>
<p>$H^t=u^t\bigodot H^{t-1}+(1-u^t)\bigodot C^t$</p>
<p>按照RNN那个理论，输出就可以是$H^t$加个激活函数了，实际上不加也没什么事。</p>
<p>论文还提出了encoder-decoder模型，个人理解：用历史的数据进行encoder，然后会得到一个$H^t$，然后我们要预测未来一段时间的数据（这部分就是decoder）。乍一看这个模型好像没什么用，但是之后文章又提出了scheduled sampling定时采样？就是我们在训练集上，我们已经知道答案，具体来说以一定概率$\epsilon$，在encoder结束后用真实值去喂decoder（1-$\epsilon $ 的概率用$H_t$去喂），在训练过程中$\epsilon$逐渐减小为0。</p>
<p>个人感觉的亮点：随机游走捕捉空间依赖，encoder-decoder模型新奇（但是否有效值得商榷）</p>
<p>疑点：文章多次提到了这个模型适用于有向图，但是实际上，数据集是无向图。。。。。。。。</p>
<h1 id="Graph-WaveNet-for-Deep-Spatial-Temporal-Graph-Modeling"><a href="#Graph-WaveNet-for-Deep-Spatial-Temporal-Graph-Modeling" class="headerlink" title="Graph WaveNet for Deep Spatial-Temporal Graph Modeling"></a>Graph WaveNet for Deep Spatial-Temporal Graph Modeling</h1><p>IJCAI 2019的文章</p>
<p>问题是一样的。模型结构分为图卷积层和时间卷积层。具体结构如下：</p>
<img src="/2022/03/07/%E8%AF%BB%E8%AE%BA%E6%96%871/graphwavenet1.png" alt="pic_1" style="zoom:70%;">

<p>GCN模块（图卷积）：显示结合了上一篇论文中的随机游走，把普通卷积$Z=\widehat{A}XW$变成了$Z=\sum_{k=0}^K P^kXW_k$，其中$P=\frac{A}{rowsum(A)}$，$P_{i,j}$表示从i到j的概率。但是这个式子只是单向的，对于有向图，式子应该变成$Z=\sum_{k=0}^K P_f^kXW_{k,1}+P_b^kXW_{k,2}$，其中$P_f=\frac{A}{rowsum(A)},P_k=\frac{A^T}{rowsum(A^T)}$。然后作者又提出了自监督邻接矩阵$\widehat{A}<em>{adp}=Softmax(Relu(E_1E_2^T))$。其中$E_1,E_2\in R^{N*c}$是学习出来的node embedding，所以最后式子变成了$Z=\sum</em>{k=0}^K P_f^kXW_{k,1}+P_b^kXW_{k,2}+\widehat{A}<em>{adp}XW</em>{k,3}$。文章还说了如果没有事先给定邻接矩阵，就可以只用最后一项。个人感觉$\widehat{A}_{adp}$是该文章的创新点。</p>
<p>TCN模块（时间）上，采用了一维因果卷积：    $(x<em>f_{1</em>k})(t)=\sum_{s=0}^{k-1}f(s)<em>{1*k}<em>x(t-s</em>d)$.这里我假设$x\in R^T,f</em>{1<em>k}\in R^k$。d表示了跳跃距离。定义$\Theta$运算为多个$f_{1</em>k}$叠加，就好像这样：</p>
<p><img src="/2022/03/07/%E8%AF%BB%E8%AE%BA%E6%96%871/graphwavenet2.png" alt="pic_2"></p>
<p>该图的$\Theta$为$f_{1<em>1},f_{1</em>2},f_{1<em>4}$叠加。设$X\in R^{N</em>D*T}$，N是点数，D是特征数，T是时间。则TCN模块的输出是：</p>
<p>$h=g(\Theta_1 \star X + b )\bigodot \sigma(\Theta_2 \star X+ c)$。g也是激活函数，这里应该是对X同一个节点，同一个特征，针对时间做1维因果卷积。</p>
<p>所以整个模块实际上就是，将输入进行线性层变化之后，分为TCN-a和b，这两部分用不同的激活函数，再用hadamard门拼接，之后再通过GCN层捕获空间依赖。最后把若干个这样的模块拼接起来，通过若干线性层和激活函数（感觉这部分就是调出来的）得到结果。Loss函数是mean absolute error（mae）函数，公式是：$L(X^{(t+1):(t+T)};\Theta)=\frac{1}{TND}\sum_{i=1}^T\sum_{j=1}^N\sum_{k=1}^D|X_{jk}^{t+i}-\widehat{X}_{j,k}^{t+i}|$</p>
<p>结果：</p>
<img src="/2022/03/07/%E8%AF%BB%E8%AE%BA%E6%96%871/graphwavenet3.png" alt="pic_3" style="zoom: 67%;">

<h1 id="Adaptive-Graph-Convolutional-Recurrent-Network-for-Traffic-Forecasting"><a href="#Adaptive-Graph-Convolutional-Recurrent-Network-for-Traffic-Forecasting" class="headerlink" title="Adaptive Graph Convolutional Recurrent Network for Traffic Forecasting"></a>Adaptive Graph Convolutional Recurrent Network for Traffic Forecasting</h1><p>NIPS 2020的文章</p>
<p>同样是交通预测问题。文章的结构大概如下：</p>
<p>空间：</p>
<p>1、优化了传统的GCN，传统GCN的公式大致是$Z=\widehat{A}X\Theta$，其中X是N * F的向量，$\Theta$是F * C的向量。矩阵乘法XW其实存在参数共用，其实对于每一个节点，都需要F * C的参数，这样才能提取出每个节点独特的特征。（这里我理解是传统GCN倾向于提取出节点的公共特征）。但是这样需要的参数$\Theta$是N * F * C，好像有点多。文章提出了矩阵分解，具体做法是让$\Theta=E_GW$，其中$E_G\in R^{N<em>d},W\in R^{d</em>F*C}$。这样的意义是，我一共有d套不同的特征，往N个节点上套。这样的话矩阵乘法得变成$z_{n,c}=\sum_{f=1}^F E_{n,f}W_{n,f,c}$.所以最后的NAPL(Node Adaptive Parameter Learning)-GCN的公式是:</p>
<p>$Z=(I_N+D^{-0.5}AD^{0.5})XE_GW+E_Gb$，记为(1)</p>
<p>2、DAGG模块，这部分参考了graph wavenet（IJCAI 2019）中的部分，大致是认为邻接矩阵A只涵盖了距离信息，然后在路网中，距离相近的路口可能交通情况完全不同（比如红绿灯长短造成影响，等等）。只用距离的邻阶矩阵不行。所以这部分有关路网信息的图用学习的方式解决。具体来说学习一个E矩阵，$E\in R^{N*d_e}$。用$EE^T$来代表$D^{-0.5}AD^{-0.5}$也就是$D^{-0.5}AD^{-0.5}=Softmax(Relu(EE^T))$。疑惑点在于如果这样的话原图的邻接矩阵是不是没用了？</p>
<p>那么(1)式子可以变成$Z=(I_N+Softmax(Relu(EE^T)))XE_GW+E_Gb$ 记为（2），并且定义算子GCN()，接受一个输入X返回(2)式的结果。</p>
<p>时间：</p>
<p>还是GRU：</p>
<p>$r^t=\sigma(GCN(X^t||H^{t-1}))$</p>
<p>$u^t=\sigma(GCN(X^t||H^{t-1}))$</p>
<p>$C^t=tanh(GCN(X^t || (r^t\bigodot H^{t-1})))$</p>
<p>$H^t=u^t\bigodot H^{t-1}+(1-u^t)\bigodot C^t$</p>
<p>和上面那个文章挺像的，也是自己定义卷积，然后魔改GRU。</p>
<h1 id="Connecting-the-Dots-Multivariate-Time-Series-Forecasting-with-Graph-Neural-Networks"><a href="#Connecting-the-Dots-Multivariate-Time-Series-Forecasting-with-Graph-Neural-Networks" class="headerlink" title="Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks"></a>Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks</h1><p>SIGKDD 2020的论文</p>
<p>这个问题难度相比于交通预测问题我感觉是更大的。具体问题是：有N个变量，每个变量有C个特征，给定过去T个时间每个变量的每个特征，要求你预测未来一小段时间，N个变量的C个特征，要求是L2损失最小。比起交通预测问题，这个问题不一定给定变量间的关系，也就是不一定有路网图的交通预测问题（交通预测是这一类问题的子集）。</p>
<p>这篇论文的作者是提出graph wavenet的作者，它把这个问题往交通预测问题上靠（用学习的方法生成图来表示变量之间的关系）</p>
<p>整体架构如下：</p>
<ul>
<li><img src="/2022/03/07/%E8%AF%BB%E8%AE%BA%E6%96%871/MTGNN1.png" alt="pic_1"></li>
</ul>
<p>最上面一个部分是图学习模块（学习变量间的关系，用一个类似邻接矩阵来表示），具体公式如下：</p>
<p>$M_1=tanh(\alpha E_1 \Theta_1),M_2=tanh(\alpha E_2 \Theta_2),A=Relu(tanh(M_1M_2^T-M_2M_1^T))$</p>
<p>接下来选定一个参数k，使得：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for i = 1 to N</span><br><span class="line">	保留A矩阵第i行前k大的数，其余清零</span><br></pre></td></tr></table></figure>

<p>而且需要注意的是A矩阵，通过激活函数括号里面的公式算出来的矩阵是满足$A_{i,j}+A_{j,i}=0$。也就是说加上激活函数后若$A_{i,j}&gt;0则A_{j,i}=0$。但我觉得这样也有一点不好（原文是说之前给的预定义图都是双向的，作者觉得不合理，但我觉得直接否认双向影响也不合理），$E_1,E_2$是初始化的node embedding，$\Theta_1,\Theta_2$是参数矩阵。文中说明了$E_1,E_2$一般就是已知节点的静态属性（比如交通预测问题中的速度，由于节点表示感知器，那么一定有一个进入感知器的属性和离开感知器的属性，对应于原文中的inflow和outflow）。而对于A的清零操作则是作者担心图太大了，要让邻接矩阵变得稀疏。</p>
<p><img src="/2022/03/07/%E8%AF%BB%E8%AE%BA%E6%96%871/MTGNN2.png" alt="pic_2"></p>
<p>接下来是图卷积模块：两个mix-hop分别处理in和out信息，并将两种信息进行合并。而具体的mix-hop如右图所示，$H_{in}$表示上一层的hidden state，$H^0=H_{in}。记$$D_{i,j}=\sum_{j}A_{i,j},\widehat{A}=D^{-1}(A+I)$。那么b部分公式如下：</p>
<p>$H^k=\beta H_{in}+(1-\beta)\widehat{A}H^{k-1}$</p>
<p>$H_{out}=\sum_{k=0}^{K}H^kW^k$。$W^k$应该是学习参数矩阵</p>
<p><img src="/2022/03/07/%E8%AF%BB%E8%AE%BA%E6%96%871/MTGNN3.png" alt="pic_3"></p>
<p>最后一部分是时间卷积，和图网络无关，也没有详细的公式，a图和前面描述的一样，也是把inflow和outflow分别送给两个dilated inception layer，而dilated inception layer就是只用一维的卷积核，然后对于同一个变量（节点），同一个特征，定义一维卷积核$f_{1*k}$：</p>
<p>​        $(z<em>f_{1</em>k})(t)=\sum_{s=0}^{k-1}f(s)_{1*k}<em>z(t-s</em>d)$,d是扩张因子，</p>
<p>dilated inception layer的输出就是：$output=concat(z<em>f_{1</em>2},z<em>f_{1</em>3},z<em>f_{1</em>6},z<em>f_{1</em>7})$</p>
<p>输出前的跳跃输出层就是把每一次通过TC和GC的输出结果结合，然后输出成一个合适的维度。</p>
<h1 id="Spatial-Temporal-Synchronous-Graph-Convolutional-Networks-A-New-Framework-for-Spatial-Temporal-Network-Data-Forecasting"><a href="#Spatial-Temporal-Synchronous-Graph-Convolutional-Networks-A-New-Framework-for-Spatial-Temporal-Network-Data-Forecasting" class="headerlink" title="Spatial-Temporal Synchronous Graph Convolutional Networks: A New Framework for Spatial-Temporal Network Data Forecasting"></a>Spatial-Temporal Synchronous Graph Convolutional Networks: A New Framework for Spatial-Temporal Network Data Forecasting</h1><p>AAAI 2020的文章。</p>
<p>前面四篇文章都是把时间、空间分开考虑，而这篇文章是直接结合起来的。个人感觉这是文章最大的亮点。</p>
<img src="/2022/03/07/%E8%AF%BB%E8%AE%BA%E6%96%871/STSGCN.png" alt="pic_1" style="zoom:60%;">



<p>在讲解STSGCM(Spatial-Temporal Synchronous Graph Convolutional Layers)前，我们需要讲一下如何结合时空做卷积。</p>
<p>一、对N*N的邻接矩阵A（假设A是带有自环的），我们把它扩大成$A’\in R^{3N *3N}$。具体来说：$A’=\left[\begin{matrix} A &amp; I_n&amp; I_n \I_n &amp; A &amp; I_n \ I_n &amp; I_n &amp; A \end{matrix}\right]$。这是因为对于每个时间片，我们要聚合上一个时刻和下一个时刻的信息，所以把前后时刻，同一个节点进行连边。</p>
<p>二、对原始的输入进行变换。原始的输入$X\in R^{N * C * T}$。N个节点，C个特征，T个时间片。我们学习两个矩阵$S_{emb}\in R^{N<em>C},T_{emb}\in R^{C</em>T}$。通过广播机制，令$X_{\mathcal G}=X+S_{emb}+T_{emb}$。这里我的理解是让输入信号本身就带有时空信息，对于时间来说，每个点都是一样的；而对于空间来说，每个时间片都是一样的。</p>
<p>STSGCM：</p>
<img src="/2022/03/07/%E8%AF%BB%E8%AE%BA%E6%96%871/STSGCN2.png" alt="pic_1" style="zoom:60%;">

<p>文章中的GCN好像并没有特别创新的地方：$h^l=GCN(h^{l-1})=g(A’h^{l-1}W+b)\in R^{3N<em>C’}$。$A’\in R^{3N</em>3N}$是上文中定义的时空邻接矩阵,$h^{l-1}\in R^{3N<em>C}$（为啥是3N不是N，因为这里需要聚合前后两个时间片的特征），$W\in R^{C</em>C’},b\in R^{C’}$g是激活函数，文章中提到了g可以是GLU，并且在实验部分说明了使用GLU效果会比较好，这样公式就变成了$h^l=(A’h^{l-1}W_1+b_1)\bigodot Sigmoid(A’h^{l-1}W_2+b_2)$。而STSGCM模块(如上图)，包含了至少两个图卷积加上一个AGG模块，AGG模块的公式是：$h_{AGG}=max(h^1,h^2,…,h^L)$，max是对矩阵中某个具体位置的数字，在L个数取最大值。在图示中L=2。$h_{AGG}\in R^{3N*C_{out}}$。然后输出模块包含了三个时间片，我们只要中间那一维。</p>
<p>我们回到最上面的那张图，注意到STSGCL实际上就是每相邻的三个时间片做STSGCM，然后做两轮。而整个模型实际上就是通过全连接层扩维度，进行STSGCL，然后再进行全连接，把维度调整为需要的输出大小。而在最后的输出时刻，我们假设当前进入输出层的输入$X\in R^{T<em>N</em>C}$，但这个T并不是一开始输入的T（只是说能表示成这个形式）。将X reshape后变成$X\in R^{N<em>TC}$。假设要预测未来R个时间步，对于$\forall i \in [1,R]$,论文中给的公式是：$y^i=Relu(XW_1^i+b_1^i)W_2^i+b_2^i$。$W_1^i\in R^{TC</em>C’},W2_i\in R^{C’*1},b_1^i\in R^{C’},b_2^i\in R$这些都是学习参数。也就是上述所谓的全连接层。</p>
<p>文章中还提到了对于邻接矩阵的变化，大概是新邻接矩阵=一个学习参数矩阵*原来的邻接矩阵：$A’_{adj}=WA’\in R^{3N *3N}$。这个思路在之前的文章中已经出现了。</p>
<p>LOSS函数：$L(Y,Y’)=\left{\begin{matrix}\frac{1}{2}(Y-Y’)^2,|Y-Y’|&lt;\delta \ \delta|Y-Y’|-\frac{1}{2}\delta^2, otherwise\end{matrix}\right.$文章说这么定义loss函数是为了防止某个数据预测差异过大，但我感觉很奇怪。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/03/07/%E8%AF%BB%E8%AE%BA%E6%96%871/" data-id="cl0gm7bmu0000i4vpc6n4hmnc" data-title="" class="article-share-link">Share</a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2021/11/12/IoTDB%E8%AF%A6%E7%BB%86%E7%89%88%E4%BB%8B%E7%BB%8D2/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">IoTDB详细版教程2</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/03/">March 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">November 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/10/">October 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/03/07/%E8%AF%BB%E8%AE%BA%E6%96%871/">(no title)</a>
          </li>
        
          <li>
            <a href="/2021/11/12/IoTDB%E8%AF%A6%E7%BB%86%E7%89%88%E4%BB%8B%E7%BB%8D2/">IoTDB详细版教程2</a>
          </li>
        
          <li>
            <a href="/2021/10/15/IoTDB%E8%AF%A6%E7%BB%86%E7%89%88%E4%BB%8B%E7%BB%8D1/">IoTDB详细版介绍1</a>
          </li>
        
          <li>
            <a href="/2021/10/08/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2022 lpf<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>